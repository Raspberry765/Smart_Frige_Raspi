{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1qTHNrvMJw5ESTok2ooYn-75dcTy6MZuB",
      "authorship_tag": "ABX9TyOg1LtxSjMVz3aO/WAQMRPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raspberry765/Smart_Frige_Raspi/blob/master/AdaCos_288.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cpp-learning.com/adacos/"
      ],
      "metadata": {
        "id": "wngoCgKwF1JX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1QO2zIDoF0Wu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# from utils import *\n",
        "# from mnist import archs\n",
        "# import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from collections import OrderedDict\n",
        "import joblib\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple"
      ],
      "metadata": {
        "id": "tPDqrRN_713B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available() and True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "ExZKzhIAGFHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),transforms.Resize((288,288)) ]\n",
        "    ) #硬貨のためのtransform\n",
        "\n",
        "train_set = datasets.MNIST(\n",
        "        root='MNIST',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform)\n",
        "\n",
        "val_set = datasets.MNIST(\n",
        "        root='MNIST',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=128,\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "\n",
        "validation_dataloader = torch.utils.data.DataLoader(\n",
        "        val_set,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        num_workers=8)"
      ],
      "metadata": {
        "id": "pVVJzHuVGW4G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_setサイズ:\", len(train_set), \"先頭10個の真値:\", [train_set[i][1] for i in range(10)])\n",
        "ds_1 = torch.utils.data.Subset(train_set, [0, 2, 5]) # 任意位置の抜き取り\n",
        "print(\"サイズ:\", len(ds_1), \"ds_1 真値 index[0, 2, 5]:\", [ds_1[i][1] for i in range(3)])\n",
        "ds_2 = torch.utils.data.ConcatDataset([ds_1, ds_1, ds_1]) # データセットを連結\n",
        "print(\"サイズ:\", len(ds_2), \"ConcatDataset([ds_1, ds_1, ds_1])の結果真値:\", [ds_2[i][1] for i in range(9)])\n",
        "\n",
        "train_val_set = torch.utils.data.ConcatDataset([train_set, val_set]) # データセットを連結\n",
        "train_val_set_loader = torch.utils.data.DataLoader(\n",
        "        train_val_set,\n",
        "        batch_size=128,\n",
        "        shuffle=True,\n",
        "        num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQm-DVIIrkNx",
        "outputId": "28485953-5120-458a-975d-1f44bc98f7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_setサイズ: 60000 先頭10個の真値: [5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
            "サイズ: 3 ds_1 真値 index[0, 2, 5]: [5, 4, 2]\n",
            "サイズ: 9 ConcatDataset([ds_1, ds_1, ds_1])の結果真値: [5, 4, 2, 5, 4, 2, 5, 4, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 各クラスのラベルを持つサンプルを1つずつ取得する。\n",
        "import matplotlib.pyplot as plt\n",
        "class_ids, sample_indices = np.unique(train_set.targets, return_index=True)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "fig.suptitle(\n",
        "    \"Examples of every class in the Fashion-MNIST dataset\", fontsize=\"x-large\"\n",
        ")\n",
        "\n",
        "for i in class_ids:\n",
        "    img = train_set.data[sample_indices[i]]\n",
        "    class_name = train_set.classes[i]\n",
        "\n",
        "    ax = fig.add_subplot(2, 5, i + 1)\n",
        "    ax.set_title(f\"{i}: {class_name}\")\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(img, cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ijiKkVg5kyJ9",
        "outputId": "786e2135-7554-45ad-e0c4-0caa730f6f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットの確認\n",
        "dataset_index=1\n",
        "print(\"データセットの数:\",len(val_set))\n",
        "print(\"データセットの情報:\", val_set[dataset_index][1])\n",
        "img =  val_set[dataset_index][0]\n",
        "img = torch.squeeze(img)\n",
        "plt.imshow(img)\n",
        "print(\"type(img):\",type(img))\n",
        "#test = MyDatasets(train_datasets,transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Yjit9DOGxraY",
        "outputId": "c7c8285e-e0b2-44b1-af2e-6e0fe0829154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データセットの数: 10000\n",
            "データセットの情報: 2\n",
            "type(img): <class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 288×288のサイズのモデル\n",
        "\n",
        "output_class = 10\n",
        "\n",
        "class Net_288(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(38088*2, 115)\n",
        "        self.fc2 = nn.Linear(115, 84)\n",
        "        self.fc3 = nn.Linear(84, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 38088*2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class NetClf(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetClf, self).__init__()\n",
        "        self.fc = nn.Linear(128, output_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        #return F.log_softmax(x,dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0S9TQJ1SGZoH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaCos(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, m=0.50):\n",
        "        super(AdaCos, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        # self.n_classes = num_classes\n",
        "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
        "        self.m = m\n",
        "        self.W = Parameter(torch.FloatTensor(num_classes, num_features))\n",
        "        nn.init.xavier_uniform_(self.W)\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # normalize features\n",
        "        x = F.normalize(input)\n",
        "        # normalize weights\n",
        "        W = F.normalize(self.W)\n",
        "        # dot product\n",
        "        logits = F.linear(x, W)\n",
        "        # add margin\n",
        "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
        "        target_logits = torch.cos(theta + self.m)\n",
        "        one_hot = torch.zeros_like(logits)\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        output = logits * (1 - one_hot) + target_logits * one_hot\n",
        "        # feature re-scale\n",
        "        with torch.no_grad():\n",
        "            B_avg = torch.where(one_hot < 1, self.s * torch.exp(logits), torch.zeros_like(logits))\n",
        "            B_avg = torch.sum(B_avg) / input.size(0)\n",
        "            # print(B_avg)\n",
        "            theta_med = torch.median(theta)\n",
        "            self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
        "        # print(self.s)\n",
        "        output *= self.s\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "dD218e4FHLIk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "aBzcrUEjHQB3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "CZ3x86jbIDGY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, metric_fc, criterion, optimizer, modelclf, optimizerclf):\n",
        "    losses = AverageMeter()\n",
        "    loss1s = AverageMeter()\n",
        "    loss2s = AverageMeter()\n",
        "    acc1s = AverageMeter()\n",
        "    acc1cs = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    metric_fc.train()\n",
        "    modelclf.train()\n",
        "\n",
        "    for i, (data, label) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "\n",
        "        feature = model(data)\n",
        "        output = metric_fc(feature, label)\n",
        "        outputc = modelclf(feature)\n",
        "        loss1 = criterion(output, label)\n",
        "        loss2 = criterion(outputc, label)\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        acc1, = accuracy(output, label, topk=(1,))\n",
        "        acc1c, = accuracy(outputc, label, topk=(1,))\n",
        "\n",
        "        losses.update(loss.item(), data.size(0))\n",
        "        loss1s.update(loss1.item(), data.size(0))\n",
        "        loss2s.update(loss2.item(), data.size(0))\n",
        "        acc1s.update(acc1.item(), data.size(0))\n",
        "        acc1cs.update(acc1c.item(), data.size(0))\n",
        "\n",
        "        # compute gradient and do optimizing step\n",
        "        optimizer.zero_grad()\n",
        "        optimizerclf.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizerclf.step()\n",
        "\n",
        "    log = OrderedDict([\n",
        "        ('loss', losses.avg),\n",
        "        ('loss1',loss1s.avg),\n",
        "        ('loss2',loss2s.avg),\n",
        "        ('acc1', acc1s.avg),\n",
        "        ('acc1c',acc1cs.avg),\n",
        "    ])\n",
        "\n",
        "    return log"
      ],
      "metadata": {
        "id": "gw1W0RpG8S0Z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def validate(val_loader, model, metric_fc, criterion):\n",
        "def validate(val_loader, model, metric_fc, criterion, modelclf):\n",
        "    losses = AverageMeter()\n",
        "    loss1s = AverageMeter()\n",
        "    loss2s = AverageMeter()\n",
        "    acc1s = AverageMeter()\n",
        "    acc1cs = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    metric_fc.eval()\n",
        "    modelclf.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, label) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
        "            data,label = data.to(device),label.to(device)\n",
        "\n",
        "            feature = model(data)\n",
        "            output = metric_fc(feature, label)\n",
        "            outputc = modelclf(feature)\n",
        "            loss1 = criterion(output, label)\n",
        "            loss2 = criterion(outputc, label)\n",
        "            loss = loss1 + loss2\n",
        "            acc1, = accuracy(output, label, topk=(1,))\n",
        "            acc1c, = accuracy(outputc, label, topk=(1,))\n",
        "\n",
        "            losses.update(loss.item(), data.size(0))\n",
        "            loss1s.update(loss1.item(), data.size(0))\n",
        "            loss2s.update(loss2.item(), data.size(0))\n",
        "            acc1s.update(acc1.item(), data.size(0))\n",
        "            acc1cs.update(acc1c.item(), data.size(0))\n",
        "\n",
        "    log = OrderedDict([\n",
        "        ('loss', losses.avg),\n",
        "        ('loss1',loss1s.avg),\n",
        "        ('loss2',loss2s.avg),\n",
        "        ('acc1', acc1s.avg),\n",
        "        ('acc1c',acc1cs.avg),\n",
        "    ])\n",
        "\n",
        "    return log"
      ],
      "metadata": {
        "id": "y8rVuTP7IIUw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "\n",
        "# class分類数をデータセットに合わせる\n",
        "# embedding用モデル\n",
        "model = Net_288().to(device)\n",
        "num_features = model.fc3.out_features\n",
        "metric_fc = AdaCos(num_features, num_classes=16).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-3)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# embeddings→16クラス分類モデル\n",
        "modelclf = NetClf().to(device)\n",
        "optimizerclf = optim.SGD(modelclf.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "dezhZ0Py8YsF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log = pd.DataFrame(index=[],\n",
        "                   columns=[ 'epoch', 'lr', 'loss', 'loss1','loss2','acc1','acc1c'\n",
        "                            , 'val_loss', 'val_loss1','val_loss2','val_acc1','val_acc1c'])\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch [%d/%d]' %(epoch+1, epochs))\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # train for one epoch\n",
        "    train_log = train(train_loader, model, metric_fc, criterion, optimizer, modelclf, optimizerclf)\n",
        "    # evaluate on validation set\n",
        "    val_log = validate(validation_dataloader, model, metric_fc, criterion, modelclf)\n",
        "    print('loss %f - acc1 %f - val_loss %f - val_acc %f'\n",
        "            %(train_log['loss'], train_log['acc1'], val_log['loss'], val_log['acc1']))\n",
        "\n",
        "    tmp = pd.Series([\n",
        "            epoch,\n",
        "            scheduler.get_lr()[0],\n",
        "            train_log['loss'],\n",
        "            train_log['loss1'],\n",
        "            train_log['loss2'],\n",
        "            train_log['acc1'],\n",
        "            train_log['acc1c'],\n",
        "            val_log['loss'],\n",
        "            val_log['loss1'],\n",
        "            val_log['loss2'],\n",
        "            val_log['acc1'],\n",
        "            val_log['acc1c'],\n",
        "        ], index=['epoch', 'lr', 'loss','loss1','loss2','acc1','acc1c'\n",
        "                  ,'val_loss','val_loss1','val_loss2', 'val_acc1','val_acc1c'])\n",
        "\n",
        "    log = log.append(tmp, ignore_index=True)\n",
        "    log.to_csv('./models_log.csv', index=False)\n",
        "\n",
        "    if val_log['loss'] < best_loss:\n",
        "        torch.save({\n",
        "            'model':model.state_dict(),\n",
        "            'metric_fc':metric_fc.state_dict(),\n",
        "            'optimizer':optimizer.state_dict(),\n",
        "            'modelclf':modelclf.state_dict(),\n",
        "            'optimizerclf':optimizerclf.state_dict(),\n",
        "        },'./model.pt')\n",
        "        best_loss = val_log['loss']\n",
        "        print(\"=> saved best model\")"
      ],
      "metadata": {
        "id": "SKQMy-knIKT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83c9263-036b-4ad8-9083-466363891883"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:41<00:00, 11.30it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.42it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 2.036300 - acc1 66.920000 - val_loss 0.876737 - val_acc 86.730000\n",
            "=> saved best model\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.99it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.03it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.772669 - acc1 88.890000 - val_loss 0.653913 - val_acc 90.660000\n",
            "=> saved best model\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.92it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.56it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.597069 - acc1 91.633333 - val_loss 0.560587 - val_acc 92.510000\n",
            "=> saved best model\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 21.63it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.507957 - acc1 93.161667 - val_loss 0.498036 - val_acc 93.590000\n",
            "=> saved best model\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.92it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.41it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.446327 - acc1 94.245000 - val_loss 0.463225 - val_acc 94.130000\n",
            "=> saved best model\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.68it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.403451 - acc1 94.960000 - val_loss 0.425534 - val_acc 94.920000\n",
            "=> saved best model\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.77it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.376076 - acc1 95.316667 - val_loss 0.416961 - val_acc 94.910000\n",
            "=> saved best model\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.38it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.348460 - acc1 95.806667 - val_loss 0.391017 - val_acc 95.330000\n",
            "=> saved best model\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.324914 - acc1 96.148333 - val_loss 0.395680 - val_acc 95.470000\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.42it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.307486 - acc1 96.541667 - val_loss 0.364355 - val_acc 96.020000\n",
            "=> saved best model\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.95it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.64it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.288355 - acc1 96.773333 - val_loss 0.361362 - val_acc 95.850000\n",
            "=> saved best model\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.269441 - acc1 97.051667 - val_loss 0.377666 - val_acc 95.830000\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.258310 - acc1 97.180000 - val_loss 0.392288 - val_acc 95.350000\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.68it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.249462 - acc1 97.416667 - val_loss 0.360072 - val_acc 96.180000\n",
            "=> saved best model\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.236025 - acc1 97.588333 - val_loss 0.363481 - val_acc 96.290000\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.76it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.228252 - acc1 97.700000 - val_loss 0.342827 - val_acc 96.490000\n",
            "=> saved best model\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.219293 - acc1 97.843333 - val_loss 0.343861 - val_acc 96.500000\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.61it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.212844 - acc1 97.915000 - val_loss 0.332915 - val_acc 96.620000\n",
            "=> saved best model\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.95it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.198215 - acc1 98.170000 - val_loss 0.340787 - val_acc 96.630000\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 469/469 [00:42<00:00, 10.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:03<00:00, 22.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.194670 - acc1 98.210000 - val_loss 0.340390 - val_acc 96.680000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "<ipython-input-25-4fbc49c38c3a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  log = log.append(tmp, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存したモデル・オプティマイザーがロードできるか確認\n",
        "model_load = Net_288().to(device)\n",
        "num_features_load = model_load.fc3.out_features\n",
        "metric_fc_load = AdaCos(num_features, num_classes=16).to(device)\n",
        "optimizer_load = optim.SGD(model_load.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
        "modelclf_load = NetClf().to(device)\n",
        "optimizerclf_load = optim.SGD(modelclf_load.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "checkpoint = torch.load('./model.pt')\n",
        "model_load.load_state_dict(checkpoint['model'])\n",
        "metric_fc_load.load_state_dict(checkpoint['metric_fc'])\n",
        "optimizer_load.load_state_dict(checkpoint['optimizer'])\n",
        "modelclf_load.load_state_dict(checkpoint['modelclf'])\n",
        "optimizerclf_load.load_state_dict(checkpoint['optimizerclf'])"
      ],
      "metadata": {
        "id": "yCwPWajQDV4L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "da=pd.read_csv('./models_log.csv')\n",
        "plt.style.use('ggplot')\n",
        "plt.plot(da[\"epoch\"],da[\"loss\"], label='train loss (loss1+loss2)')\n",
        "plt.plot(da[\"epoch\"],da[\"loss1\"], label='train loss1 (embed)')\n",
        "plt.plot(da[\"epoch\"],da[\"loss2\"], label='train loss2 (clf)')\n",
        "plt.plot(da[\"epoch\"],da[\"val_loss\"], label='val loss (loss1+loss2)')\n",
        "plt.plot(da[\"epoch\"],da[\"val_loss1\"], label='val loss1 (embed)')\n",
        "plt.plot(da[\"epoch\"],da[\"val_loss2\"], label='val loss2 (clf)')\n",
        "plt.legend(loc=\"center left\",bbox_to_anchor=(1.02,0.5,), borderaxespad=0)\n",
        "plt.xticks(np.arange(0, len(da[\"epoch\"]), step=1))\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('LOSS[%]')\n",
        "plt.title('loss')\n",
        "#plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "yEaU62UjDcTd",
        "outputId": "6a975c9c-7f99-425b-8a36-5b9c0f096440"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.plot(da[\"acc1\"], label='train acc1 (embed)')\n",
        "plt.plot(da[\"acc1c\"], label='train acc1c (clf)')\n",
        "plt.plot(da[\"val_acc1\"], label='valid acc1 (embed)')\n",
        "plt.plot(da[\"val_acc1c\"], label='valid acc1c (clf)')\n",
        "plt.xticks(np.arange(0, len(da[\"epoch\"]), step=1))\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('ACCURACY[%]')\n",
        "#plt.legend(['train acc', 'val acc'])\n",
        "plt.legend(loc=\"center left\",bbox_to_anchor=(1.02,0.5,), borderaxespad=0)\n",
        "plt.title('accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "_5MgM1N_Dvqo",
        "outputId": "5d090794-d8ad-4095-c49d-b34c5f46d2a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "results = np.zeros((1,128))\n",
        "for img, label in tqdm(train_loader):\n",
        "    img, label = img.to(device), label.to(device)\n",
        "    pred = model(img)\n",
        "    #print(pred.shape)\n",
        "    pred_num = pred.to(\"cpu\").detach().numpy().copy()\n",
        "    print(results.shape)\n",
        "    results = np.concatenate([results, pred_num])\n",
        "\n",
        "print(results.shape)\n",
        "results[0,:]\n",
        "\n",
        "results_del = np.delete(results, 0, 0)\n",
        "print(results_del)\n",
        "print(results_del.shape)\n",
        "\n",
        "clf = LocalOutlierFactor(n_neighbors=22, novelty=True, contamination=0.0001)\n",
        "clf.fit(results_del)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rvpU_hLmflMm",
        "outputId": "85f4bd0e-e1c6-4aef-933a-0afd5be195f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  1%|          | 3/469 [00:00<01:33,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128)\n",
            "(129, 128)\n",
            "(257, 128)\n",
            "(385, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 7/469 [00:00<00:47,  9.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(513, 128)\n",
            "(641, 128)\n",
            "(769, 128)\n",
            "(897, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 12/469 [00:01<00:31, 14.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1025, 128)\n",
            "(1153, 128)\n",
            "(1281, 128)\n",
            "(1409, 128)\n",
            "(1537, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 18/469 [00:01<00:24, 18.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1665, 128)\n",
            "(1793, 128)\n",
            "(1921, 128)\n",
            "(2049, 128)\n",
            "(2177, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 21/469 [00:01<00:21, 20.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2305, 128)\n",
            "(2433, 128)\n",
            "(2561, 128)\n",
            "(2689, 128)\n",
            "(2817, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 27/469 [00:01<00:19, 22.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2945, 128)\n",
            "(3073, 128)\n",
            "(3201, 128)\n",
            "(3329, 128)\n",
            "(3457, 128)\n",
            "(3585, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 33/469 [00:02<00:19, 22.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3713, 128)\n",
            "(3841, 128)\n",
            "(3969, 128)\n",
            "(4097, 128)\n",
            "(4225, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 39/469 [00:02<00:18, 23.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4353, 128)\n",
            "(4481, 128)\n",
            "(4609, 128)\n",
            "(4737, 128)\n",
            "(4865, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 42/469 [00:02<00:17, 23.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4993, 128)\n",
            "(5121, 128)\n",
            "(5249, 128)\n",
            "(5377, 128)\n",
            "(5505, 128)\n",
            "(5633, 128)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 48/469 [00:02<00:18, 23.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(5761, 128)\n",
            "(5889, 128)\n",
            "(6017, 128)\n",
            "(6145, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 54/469 [00:03<00:18, 22.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6273, 128)\n",
            "(6401, 128)\n",
            "(6529, 128)\n",
            "(6657, 128)\n",
            "(6785, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 57/469 [00:03<00:17, 23.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6913, 128)\n",
            "(7041, 128)\n",
            "(7169, 128)\n",
            "(7297, 128)\n",
            "(7425, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 63/469 [00:03<00:17, 23.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7553, 128)\n",
            "(7681, 128)\n",
            "(7809, 128)\n",
            "(7937, 128)\n",
            "(8065, 128)\n",
            "(8193, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 69/469 [00:03<00:16, 23.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8321, 128)\n",
            "(8449, 128)\n",
            "(8577, 128)\n",
            "(8705, 128)\n",
            "(8833, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 75/469 [00:03<00:16, 24.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8961, 128)\n",
            "(9089, 128)\n",
            "(9217, 128)\n",
            "(9345, 128)\n",
            "(9473, 128)\n",
            "(9601, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 81/469 [00:04<00:15, 24.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9729, 128)\n",
            "(9857, 128)\n",
            "(9985, 128)\n",
            "(10113, 128)\n",
            "(10241, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 84/469 [00:04<00:16, 23.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10369, 128)\n",
            "(10497, 128)\n",
            "(10625, 128)\n",
            "(10753, 128)\n",
            "(10881, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 90/469 [00:04<00:15, 24.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11009, 128)\n",
            "(11137, 128)\n",
            "(11265, 128)\n",
            "(11393, 128)\n",
            "(11521, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 96/469 [00:04<00:15, 23.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11649, 128)\n",
            "(11777, 128)\n",
            "(11905, 128)\n",
            "(12033, 128)\n",
            "(12161, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 99/469 [00:04<00:16, 22.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12289, 128)\n",
            "(12417, 128)\n",
            "(12545, 128)\n",
            "(12673, 128)\n",
            "(12801, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 105/469 [00:05<00:16, 22.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12929, 128)\n",
            "(13057, 128)\n",
            "(13185, 128)\n",
            "(13313, 128)\n",
            "(13441, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 111/469 [00:05<00:15, 22.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13569, 128)\n",
            "(13697, 128)\n",
            "(13825, 128)\n",
            "(13953, 128)\n",
            "(14081, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 114/469 [00:05<00:15, 22.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14209, 128)\n",
            "(14337, 128)\n",
            "(14465, 128)\n",
            "(14593, 128)\n",
            "(14721, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 120/469 [00:05<00:15, 22.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14849, 128)\n",
            "(14977, 128)\n",
            "(15105, 128)\n",
            "(15233, 128)\n",
            "(15361, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 126/469 [00:06<00:15, 22.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15489, 128)\n",
            "(15617, 128)\n",
            "(15745, 128)\n",
            "(15873, 128)\n",
            "(16001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 129/469 [00:06<00:15, 21.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16129, 128)\n",
            "(16257, 128)\n",
            "(16385, 128)\n",
            "(16513, 128)\n",
            "(16641, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 135/469 [00:06<00:15, 21.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16769, 128)\n",
            "(16897, 128)\n",
            "(17025, 128)\n",
            "(17153, 128)\n",
            "(17281, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 141/469 [00:06<00:15, 21.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17409, 128)\n",
            "(17537, 128)\n",
            "(17665, 128)\n",
            "(17793, 128)\n",
            "(17921, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 144/469 [00:06<00:14, 21.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18049, 128)\n",
            "(18177, 128)\n",
            "(18305, 128)\n",
            "(18433, 128)\n",
            "(18561, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 150/469 [00:07<00:14, 22.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18689, 128)\n",
            "(18817, 128)\n",
            "(18945, 128)\n",
            "(19073, 128)\n",
            "(19201, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 156/469 [00:07<00:14, 22.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19329, 128)\n",
            "(19457, 128)\n",
            "(19585, 128)\n",
            "(19713, 128)\n",
            "(19841, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 159/469 [00:07<00:13, 22.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19969, 128)\n",
            "(20097, 128)\n",
            "(20225, 128)\n",
            "(20353, 128)\n",
            "(20481, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 165/469 [00:07<00:13, 22.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20609, 128)\n",
            "(20737, 128)\n",
            "(20865, 128)\n",
            "(20993, 128)\n",
            "(21121, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 171/469 [00:08<00:13, 22.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21249, 128)\n",
            "(21377, 128)\n",
            "(21505, 128)\n",
            "(21633, 128)\n",
            "(21761, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 174/469 [00:08<00:13, 22.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21889, 128)\n",
            "(22017, 128)\n",
            "(22145, 128)\n",
            "(22273, 128)\n",
            "(22401, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 180/469 [00:08<00:13, 21.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22529, 128)\n",
            "(22657, 128)\n",
            "(22785, 128)\n",
            "(22913, 128)\n",
            "(23041, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 186/469 [00:08<00:12, 21.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23169, 128)\n",
            "(23297, 128)\n",
            "(23425, 128)\n",
            "(23553, 128)\n",
            "(23681, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 189/469 [00:08<00:12, 22.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23809, 128)\n",
            "(23937, 128)\n",
            "(24065, 128)\n",
            "(24193, 128)\n",
            "(24321, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 195/469 [00:09<00:12, 21.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24449, 128)\n",
            "(24577, 128)\n",
            "(24705, 128)\n",
            "(24833, 128)\n",
            "(24961, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 201/469 [00:09<00:12, 21.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25089, 128)\n",
            "(25217, 128)\n",
            "(25345, 128)\n",
            "(25473, 128)\n",
            "(25601, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 204/469 [00:09<00:12, 21.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25729, 128)\n",
            "(25857, 128)\n",
            "(25985, 128)\n",
            "(26113, 128)\n",
            "(26241, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 210/469 [00:09<00:11, 21.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26369, 128)\n",
            "(26497, 128)\n",
            "(26625, 128)\n",
            "(26753, 128)\n",
            "(26881, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 216/469 [00:10<00:11, 21.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27009, 128)\n",
            "(27137, 128)\n",
            "(27265, 128)\n",
            "(27393, 128)\n",
            "(27521, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 219/469 [00:10<00:11, 21.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27649, 128)\n",
            "(27777, 128)\n",
            "(27905, 128)\n",
            "(28033, 128)\n",
            "(28161, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 225/469 [00:10<00:11, 20.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28289, 128)\n",
            "(28417, 128)\n",
            "(28545, 128)\n",
            "(28673, 128)\n",
            "(28801, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 231/469 [00:10<00:11, 20.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28929, 128)\n",
            "(29057, 128)\n",
            "(29185, 128)\n",
            "(29313, 128)\n",
            "(29441, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 234/469 [00:11<00:11, 20.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29569, 128)\n",
            "(29697, 128)\n",
            "(29825, 128)\n",
            "(29953, 128)\n",
            "(30081, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 240/469 [00:11<00:10, 21.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30209, 128)\n",
            "(30337, 128)\n",
            "(30465, 128)\n",
            "(30593, 128)\n",
            "(30721, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 246/469 [00:11<00:10, 21.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30849, 128)\n",
            "(30977, 128)\n",
            "(31105, 128)\n",
            "(31233, 128)\n",
            "(31361, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 249/469 [00:11<00:10, 20.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31489, 128)\n",
            "(31617, 128)\n",
            "(31745, 128)\n",
            "(31873, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 255/469 [00:12<00:10, 20.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32001, 128)\n",
            "(32129, 128)\n",
            "(32257, 128)\n",
            "(32385, 128)\n",
            "(32513, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 258/469 [00:12<00:10, 20.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32641, 128)\n",
            "(32769, 128)\n",
            "(32897, 128)\n",
            "(33025, 128)\n",
            "(33153, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 264/469 [00:12<00:09, 20.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33281, 128)\n",
            "(33409, 128)\n",
            "(33537, 128)\n",
            "(33665, 128)\n",
            "(33793, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 267/469 [00:12<00:09, 20.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33921, 128)\n",
            "(34049, 128)\n",
            "(34177, 128)\n",
            "(34305, 128)\n",
            "(34433, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 273/469 [00:13<00:09, 20.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34561, 128)\n",
            "(34689, 128)\n",
            "(34817, 128)\n",
            "(34945, 128)\n",
            "(35073, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 279/469 [00:13<00:09, 20.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35201, 128)\n",
            "(35329, 128)\n",
            "(35457, 128)\n",
            "(35585, 128)\n",
            "(35713, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 282/469 [00:13<00:09, 20.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35841, 128)\n",
            "(35969, 128)\n",
            "(36097, 128)\n",
            "(36225, 128)\n",
            "(36353, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 288/469 [00:13<00:08, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36481, 128)\n",
            "(36609, 128)\n",
            "(36737, 128)\n",
            "(36865, 128)\n",
            "(36993, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 294/469 [00:14<00:08, 20.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37121, 128)\n",
            "(37249, 128)\n",
            "(37377, 128)\n",
            "(37505, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 297/469 [00:14<00:08, 20.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37633, 128)\n",
            "(37761, 128)\n",
            "(37889, 128)\n",
            "(38017, 128)\n",
            "(38145, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 303/469 [00:14<00:08, 19.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38273, 128)\n",
            "(38401, 128)\n",
            "(38529, 128)\n",
            "(38657, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 306/469 [00:14<00:08, 20.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38785, 128)\n",
            "(38913, 128)\n",
            "(39041, 128)\n",
            "(39169, 128)\n",
            "(39297, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 311/469 [00:14<00:07, 19.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39425, 128)\n",
            "(39553, 128)\n",
            "(39681, 128)\n",
            "(39809, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 316/469 [00:15<00:07, 20.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39937, 128)\n",
            "(40065, 128)\n",
            "(40193, 128)\n",
            "(40321, 128)\n",
            "(40449, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 319/469 [00:15<00:07, 19.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40577, 128)\n",
            "(40705, 128)\n",
            "(40833, 128)\n",
            "(40961, 128)\n",
            "(41089, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 325/469 [00:15<00:07, 20.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41217, 128)\n",
            "(41345, 128)\n",
            "(41473, 128)\n",
            "(41601, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 330/469 [00:15<00:07, 19.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41729, 128)\n",
            "(41857, 128)\n",
            "(41985, 128)\n",
            "(42113, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 332/469 [00:15<00:07, 19.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42241, 128)\n",
            "(42369, 128)\n",
            "(42497, 128)\n",
            "(42625, 128)\n",
            "(42753, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 339/469 [00:16<00:06, 19.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42881, 128)\n",
            "(43009, 128)\n",
            "(43137, 128)\n",
            "(43265, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 342/469 [00:16<00:06, 19.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43393, 128)\n",
            "(43521, 128)\n",
            "(43649, 128)\n",
            "(43777, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 346/469 [00:16<00:06, 19.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43905, 128)\n",
            "(44033, 128)\n",
            "(44161, 128)\n",
            "(44289, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 350/469 [00:16<00:06, 19.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44417, 128)\n",
            "(44545, 128)\n",
            "(44673, 128)\n",
            "(44801, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 354/469 [00:17<00:06, 18.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44929, 128)\n",
            "(45057, 128)\n",
            "(45185, 128)\n",
            "(45313, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 358/469 [00:17<00:06, 17.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45441, 128)\n",
            "(45569, 128)\n",
            "(45697, 128)\n",
            "(45825, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 362/469 [00:17<00:05, 18.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45953, 128)\n",
            "(46081, 128)\n",
            "(46209, 128)\n",
            "(46337, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 366/469 [00:17<00:05, 17.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(46465, 128)\n",
            "(46593, 128)\n",
            "(46721, 128)\n",
            "(46849, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 370/469 [00:18<00:05, 17.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(46977, 128)\n",
            "(47105, 128)\n",
            "(47233, 128)\n",
            "(47361, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 374/469 [00:18<00:05, 18.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47489, 128)\n",
            "(47617, 128)\n",
            "(47745, 128)\n",
            "(47873, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 378/469 [00:18<00:04, 18.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48001, 128)\n",
            "(48129, 128)\n",
            "(48257, 128)\n",
            "(48385, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 382/469 [00:18<00:04, 17.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48513, 128)\n",
            "(48641, 128)\n",
            "(48769, 128)\n",
            "(48897, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 386/469 [00:18<00:04, 17.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49025, 128)\n",
            "(49153, 128)\n",
            "(49281, 128)\n",
            "(49409, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 390/469 [00:19<00:04, 17.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49537, 128)\n",
            "(49665, 128)\n",
            "(49793, 128)\n",
            "(49921, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 394/469 [00:19<00:04, 17.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50049, 128)\n",
            "(50177, 128)\n",
            "(50305, 128)\n",
            "(50433, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 398/469 [00:19<00:04, 17.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50561, 128)\n",
            "(50689, 128)\n",
            "(50817, 128)\n",
            "(50945, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 402/469 [00:19<00:03, 17.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51073, 128)\n",
            "(51201, 128)\n",
            "(51329, 128)\n",
            "(51457, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 406/469 [00:20<00:03, 17.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51585, 128)\n",
            "(51713, 128)\n",
            "(51841, 128)\n",
            "(51969, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 410/469 [00:20<00:03, 17.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(52097, 128)\n",
            "(52225, 128)\n",
            "(52353, 128)\n",
            "(52481, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 414/469 [00:20<00:03, 17.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(52609, 128)\n",
            "(52737, 128)\n",
            "(52865, 128)\n",
            "(52993, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 418/469 [00:20<00:02, 17.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53121, 128)\n",
            "(53249, 128)\n",
            "(53377, 128)\n",
            "(53505, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 422/469 [00:21<00:02, 17.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53633, 128)\n",
            "(53761, 128)\n",
            "(53889, 128)\n",
            "(54017, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 426/469 [00:21<00:02, 17.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54145, 128)\n",
            "(54273, 128)\n",
            "(54401, 128)\n",
            "(54529, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 430/469 [00:21<00:02, 17.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54657, 128)\n",
            "(54785, 128)\n",
            "(54913, 128)\n",
            "(55041, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 434/469 [00:21<00:02, 17.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55169, 128)\n",
            "(55297, 128)\n",
            "(55425, 128)\n",
            "(55553, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 438/469 [00:21<00:01, 16.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55681, 128)\n",
            "(55809, 128)\n",
            "(55937, 128)\n",
            "(56065, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 442/469 [00:22<00:01, 16.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56193, 128)\n",
            "(56321, 128)\n",
            "(56449, 128)\n",
            "(56577, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 446/469 [00:22<00:01, 16.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56705, 128)\n",
            "(56833, 128)\n",
            "(56961, 128)\n",
            "(57089, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 450/469 [00:22<00:01, 16.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57217, 128)\n",
            "(57345, 128)\n",
            "(57473, 128)\n",
            "(57601, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 454/469 [00:22<00:00, 16.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57729, 128)\n",
            "(57857, 128)\n",
            "(57985, 128)\n",
            "(58113, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 458/469 [00:23<00:00, 16.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58241, 128)\n",
            "(58369, 128)\n",
            "(58497, 128)\n",
            "(58625, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 462/469 [00:23<00:00, 16.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58753, 128)\n",
            "(58881, 128)\n",
            "(59009, 128)\n",
            "(59137, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 466/469 [00:23<00:00, 17.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59265, 128)\n",
            "(59393, 128)\n",
            "(59521, 128)\n",
            "(59649, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:23<00:00, 19.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59777, 128)\n",
            "(59905, 128)\n",
            "(60001, 128)\n",
            "[[ -1.00171566   1.05965006  -3.48599863 ...   4.0500536    4.04054642\n",
            "    6.34762383]\n",
            " [  7.01109123  -1.29637301  10.51177979 ...   1.9429971   -1.16567874\n",
            "    1.99914801]\n",
            " [  6.26605988  10.92573643  -9.06562138 ...   6.11639023 -10.12888527\n",
            "  -13.92168808]\n",
            " ...\n",
            " [ -0.66690016   0.75087184  -2.84898448 ...   3.07780266   3.02376914\n",
            "    4.2856369 ]\n",
            " [  1.72064888  -6.89955711   4.31515408 ...  -5.89400482   1.65278649\n",
            "    5.54637909]\n",
            " [ -3.77616453   6.99940109  -7.30829239 ...  -6.5223608   -1.17120922\n",
            "   -1.72933161]]\n",
            "(60000, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LocalOutlierFactor(contamination=0.0001, n_neighbors=22, novelty=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(contamination=0.0001, n_neighbors=22, novelty=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LocalOutlierFactor</label><div class=\"sk-toggleable__content\"><pre>LocalOutlierFactor(contamination=0.0001, n_neighbors=22, novelty=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST testで実施\n",
        "\n",
        "val_results = np.zeros((1,128))\n",
        "for img, label in tqdm(validation_dataloader):\n",
        "    img, label = img.to(device), label.to(device)\n",
        "    pred = model(img)\n",
        "    #print(pred.shape)\n",
        "    pred_num = pred.to(\"cpu\").detach().numpy().copy()\n",
        "    print(val_results.shape)\n",
        "    val_results = np.concatenate([val_results, pred_num])\n",
        "\n",
        "val_results_del = np.delete(val_results, 0, 0)\n",
        "print(val_results_del)\n",
        "print(val_results_del.shape)\n",
        "\n",
        "y_pred_test = clf.predict(val_results_del)\n",
        "n_error_test = y_pred_test[y_pred_test == -1].size\n",
        "print(n_error_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpBv0RKgXjz",
        "outputId": "c9a599ae-be92-4857-fe88-344a7522b323"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  4%|▍         | 3/79 [00:00<00:16,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128)\n",
            "(129, 128)\n",
            "(257, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 7/79 [00:00<00:07, 10.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(385, 128)\n",
            "(513, 128)\n",
            "(641, 128)\n",
            "(769, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 10/79 [00:01<00:05, 13.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(897, 128)\n",
            "(1025, 128)\n",
            "(1153, 128)\n",
            "(1281, 128)\n",
            "(1409, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 16/79 [00:01<00:03, 19.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1537, 128)\n",
            "(1665, 128)\n",
            "(1793, 128)\n",
            "(1921, 128)\n",
            "(2049, 128)\n",
            "(2177, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 22/79 [00:01<00:02, 22.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2305, 128)\n",
            "(2433, 128)\n",
            "(2561, 128)\n",
            "(2689, 128)\n",
            "(2817, 128)\n",
            "(2945, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 28/79 [00:01<00:02, 22.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3073, 128)\n",
            "(3201, 128)\n",
            "(3329, 128)\n",
            "(3457, 128)\n",
            "(3585, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 34/79 [00:02<00:01, 23.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3713, 128)\n",
            "(3841, 128)\n",
            "(3969, 128)\n",
            "(4097, 128)\n",
            "(4225, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 37/79 [00:02<00:01, 23.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4353, 128)\n",
            "(4481, 128)\n",
            "(4609, 128)\n",
            "(4737, 128)\n",
            "(4865, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 43/79 [00:02<00:01, 23.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4993, 128)\n",
            "(5121, 128)\n",
            "(5249, 128)\n",
            "(5377, 128)\n",
            "(5505, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 49/79 [00:02<00:01, 23.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5633, 128)\n",
            "(5761, 128)\n",
            "(5889, 128)\n",
            "(6017, 128)\n",
            "(6145, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 52/79 [00:02<00:01, 22.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6273, 128)\n",
            "(6401, 128)\n",
            "(6529, 128)\n",
            "(6657, 128)\n",
            "(6785, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 58/79 [00:03<00:00, 23.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6913, 128)\n",
            "(7041, 128)\n",
            "(7169, 128)\n",
            "(7297, 128)\n",
            "(7425, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 64/79 [00:03<00:00, 22.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7553, 128)\n",
            "(7681, 128)\n",
            "(7809, 128)\n",
            "(7937, 128)\n",
            "(8065, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 70/79 [00:03<00:00, 24.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8193, 128)\n",
            "(8321, 128)\n",
            "(8449, 128)\n",
            "(8577, 128)\n",
            "(8705, 128)\n",
            "(8833, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 76/79 [00:03<00:00, 24.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8961, 128)\n",
            "(9089, 128)\n",
            "(9217, 128)\n",
            "(9345, 128)\n",
            "(9473, 128)\n",
            "(9601, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 79/79 [00:04<00:00, 19.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9729, 128)\n",
            "(9857, 128)\n",
            "(9985, 128)\n",
            "[[ 12.53729534  -2.66704226   8.22725582 ... -11.23935318   5.53199148\n",
            "    9.36045456]\n",
            " [-11.43770027   5.21248531  14.76675987 ...  13.14024734  15.41799831\n",
            "    1.6471858 ]\n",
            " [  0.63262796  -4.64468956   3.26128078 ...  -4.11147594   0.9293102\n",
            "    3.6590488 ]\n",
            " ...\n",
            " [ 10.23930931   8.3204155  -11.1435318  ...   9.42584133   8.72609234\n",
            "   -1.36526251]\n",
            " [-10.40469456  -0.19860768   9.18360043 ...  -3.19581842  -5.03900862\n",
            "   -0.42783004]\n",
            " [  5.94463873  11.32964897  -8.32512379 ...   5.50158691 -11.30411243\n",
            "  -15.56324768]]\n",
            "(10000, 128)\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_train_dataset = datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=True, transform=transform, download=True\n",
        ")\n",
        "fashion_train_data_loader = torch.utils.data.DataLoader(\n",
        "    fashion_train_dataset, batch_size=64, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugzw_NMUEyaI",
        "outputId": "45b910a5-561c-41f0-ad01-fa19a490b751"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10451044.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz to datasets/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 172478.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz to datasets/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3275126.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to datasets/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5767168.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to datasets/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_fashion_results = np.zeros((1,128))\n",
        "for img, label in tqdm(fashion_train_data_loader):\n",
        "    img, label = img.to(device), label.to(device)\n",
        "    pred = model(img)\n",
        "    #print(pred.shape)\n",
        "    pred_num = pred.to(\"cpu\").detach().numpy().copy()\n",
        "    print(val_results.shape)\n",
        "    val_fashion_results = np.concatenate([val_fashion_results, pred_num])\n",
        "\n",
        "val_fashion_results_del = np.delete(val_fashion_results, 0, 0)\n",
        "print(val_fashion_results_del)\n",
        "print(val_fashion_results_del.shape)\n",
        "\n",
        "y_pred_test = clf.predict(val_fashion_results_del)\n",
        "n_error_test = y_pred_test[y_pred_test == -1].size\n",
        "print(n_error_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OOoktEaFVDP",
        "outputId": "5f5959de-9f64-437d-ff38-940e2b06f3fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "  0%|          | 4/938 [00:00<00:52, 17.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 8/938 [00:00<00:49, 18.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 12/938 [00:00<00:49, 18.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 16/938 [00:00<00:49, 18.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 19/938 [00:01<00:47, 19.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 24/938 [00:01<00:46, 19.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 28/938 [00:01<00:47, 19.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 32/938 [00:01<00:46, 19.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 37/938 [00:01<00:45, 19.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 42/938 [00:02<00:44, 19.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 47/938 [00:02<00:44, 19.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 51/938 [00:02<00:45, 19.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 56/938 [00:02<00:44, 19.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 59/938 [00:03<00:44, 19.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 65/938 [00:03<00:44, 19.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 69/938 [00:03<00:44, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 73/938 [00:03<00:44, 19.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 77/938 [00:03<00:44, 19.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 82/938 [00:04<00:42, 19.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 88/938 [00:04<00:42, 20.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 92/938 [00:04<00:42, 19.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 96/938 [00:04<00:43, 19.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 100/938 [00:05<00:43, 19.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 104/938 [00:05<00:43, 19.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 106/938 [00:05<00:43, 18.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 111/938 [00:05<00:44, 18.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 115/938 [00:05<00:43, 18.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 119/938 [00:06<00:43, 18.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 123/938 [00:06<00:42, 19.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 127/938 [00:06<00:42, 18.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 131/938 [00:06<00:42, 19.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 135/938 [00:06<00:41, 19.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 140/938 [00:07<00:40, 19.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 144/938 [00:07<00:40, 19.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 148/938 [00:07<00:40, 19.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 152/938 [00:07<00:40, 19.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 156/938 [00:08<00:42, 18.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 160/938 [00:08<00:46, 16.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 164/938 [00:08<00:48, 16.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 168/938 [00:08<00:47, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 172/938 [00:09<00:45, 16.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 176/938 [00:09<00:46, 16.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 180/938 [00:09<00:45, 16.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 184/938 [00:09<00:42, 17.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 188/938 [00:09<00:40, 18.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 192/938 [00:10<00:39, 18.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 196/938 [00:10<00:39, 18.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 200/938 [00:10<00:39, 18.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 204/938 [00:10<00:38, 18.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 208/938 [00:11<00:39, 18.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 212/938 [00:11<00:40, 18.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 216/938 [00:11<00:39, 18.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 220/938 [00:11<00:39, 18.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 224/938 [00:11<00:40, 17.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 228/938 [00:12<00:39, 17.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 232/938 [00:12<00:39, 17.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 236/938 [00:12<00:38, 18.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 240/938 [00:12<00:37, 18.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 244/938 [00:13<00:36, 18.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 248/938 [00:13<00:36, 18.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 252/938 [00:13<00:36, 18.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 256/938 [00:13<00:37, 18.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 260/938 [00:13<00:36, 18.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 264/938 [00:14<00:36, 18.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 268/938 [00:14<00:36, 18.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 272/938 [00:14<00:35, 18.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 276/938 [00:14<00:36, 18.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 280/938 [00:14<00:36, 17.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 284/938 [00:15<00:35, 18.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 288/938 [00:15<00:35, 18.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 292/938 [00:15<00:34, 18.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 296/938 [00:15<00:34, 18.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 300/938 [00:16<00:34, 18.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 304/938 [00:16<00:34, 18.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 308/938 [00:16<00:35, 17.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 312/938 [00:16<00:34, 18.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 316/938 [00:16<00:34, 18.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 320/938 [00:17<00:33, 18.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 324/938 [00:17<00:33, 18.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 328/938 [00:17<00:33, 18.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 332/938 [00:17<00:32, 18.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 336/938 [00:18<00:33, 17.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 340/938 [00:18<00:33, 17.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 344/938 [00:18<00:33, 17.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 348/938 [00:18<00:33, 17.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 352/938 [00:18<00:32, 17.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 356/938 [00:19<00:32, 17.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 360/938 [00:19<00:33, 17.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 364/938 [00:19<00:34, 16.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 368/938 [00:19<00:34, 16.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 372/938 [00:20<00:34, 16.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 374/938 [00:20<00:34, 16.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 378/938 [00:20<00:36, 15.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 380/938 [00:20<00:36, 15.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 386/938 [00:21<00:33, 16.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 390/938 [00:21<00:32, 16.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 394/938 [00:21<00:30, 17.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 398/938 [00:21<00:31, 17.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 402/938 [00:21<00:32, 16.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 406/938 [00:22<00:31, 16.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 410/938 [00:22<00:30, 17.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 414/938 [00:22<00:30, 17.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 418/938 [00:22<00:30, 16.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 422/938 [00:23<00:31, 16.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 426/938 [00:23<00:31, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 430/938 [00:23<00:29, 17.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 434/938 [00:23<00:29, 17.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 438/938 [00:24<00:30, 16.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 442/938 [00:24<00:29, 16.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 446/938 [00:24<00:28, 17.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 450/938 [00:24<00:29, 16.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 454/938 [00:25<00:28, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 458/938 [00:25<00:27, 17.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 462/938 [00:25<00:28, 16.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 464/938 [00:25<00:29, 16.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 468/938 [00:25<00:30, 15.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 472/938 [00:26<00:31, 14.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 476/938 [00:26<00:30, 15.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 480/938 [00:26<00:29, 15.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 484/938 [00:26<00:28, 15.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 488/938 [00:27<00:27, 16.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 492/938 [00:27<00:25, 17.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 496/938 [00:27<00:25, 17.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 500/938 [00:27<00:26, 16.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 504/938 [00:28<00:25, 17.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 508/938 [00:28<00:25, 17.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 512/938 [00:28<00:24, 17.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 516/938 [00:28<00:24, 17.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 520/938 [00:29<00:24, 16.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 524/938 [00:29<00:25, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 526/938 [00:29<00:26, 15.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 532/938 [00:29<00:25, 15.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 536/938 [00:30<00:25, 15.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 540/938 [00:30<00:24, 16.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 544/938 [00:30<00:23, 16.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 548/938 [00:30<00:24, 16.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 550/938 [00:30<00:24, 15.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 554/938 [00:31<00:25, 15.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 558/938 [00:31<00:26, 14.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 560/938 [00:31<00:25, 14.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 564/938 [00:31<00:25, 14.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 566/938 [00:32<00:25, 14.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 570/938 [00:32<00:24, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 574/938 [00:32<00:24, 14.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 578/938 [00:32<00:23, 15.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 582/938 [00:33<00:23, 15.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 584/938 [00:33<00:24, 14.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 588/938 [00:33<00:23, 14.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 590/938 [00:33<00:23, 14.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 594/938 [00:33<00:22, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 598/938 [00:34<00:23, 14.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 602/938 [00:34<00:24, 13.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 604/938 [00:34<00:23, 14.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 610/938 [00:35<00:21, 15.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 612/938 [00:35<00:21, 15.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 616/938 [00:35<00:21, 14.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 620/938 [00:35<00:21, 14.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 624/938 [00:35<00:20, 15.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 626/938 [00:36<00:20, 15.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 632/938 [00:36<00:20, 15.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 634/938 [00:36<00:20, 15.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 638/938 [00:36<00:19, 15.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 642/938 [00:37<00:19, 15.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 646/938 [00:37<00:19, 15.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 648/938 [00:37<00:18, 15.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 652/938 [00:37<00:18, 15.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 656/938 [00:38<00:19, 14.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 658/938 [00:38<00:18, 14.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 662/938 [00:38<00:18, 14.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 666/938 [00:38<00:17, 15.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 668/938 [00:38<00:18, 14.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 672/938 [00:39<00:17, 15.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 676/938 [00:39<00:17, 14.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 680/938 [00:39<00:17, 14.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 682/938 [00:39<00:17, 14.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 686/938 [00:40<00:16, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 690/938 [00:40<00:16, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 694/938 [00:40<00:16, 14.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 698/938 [00:40<00:16, 14.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 700/938 [00:41<00:16, 14.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 704/938 [00:41<00:16, 14.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 706/938 [00:41<00:16, 14.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 710/938 [00:41<00:15, 14.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 714/938 [00:42<00:15, 14.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 718/938 [00:42<00:15, 14.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 722/938 [00:42<00:15, 13.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 724/938 [00:42<00:16, 13.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 728/938 [00:43<00:15, 13.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 730/938 [00:43<00:15, 13.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 734/938 [00:43<00:15, 13.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 736/938 [00:43<00:15, 13.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 740/938 [00:43<00:15, 13.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 742/938 [00:44<00:14, 13.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 746/938 [00:44<00:13, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 748/938 [00:44<00:13, 14.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 752/938 [00:44<00:13, 13.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 754/938 [00:44<00:13, 14.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 758/938 [00:45<00:12, 14.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 760/938 [00:45<00:12, 14.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 764/938 [00:45<00:12, 14.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 766/938 [00:45<00:11, 14.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 770/938 [00:46<00:11, 14.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 772/938 [00:46<00:11, 14.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 776/938 [00:46<00:11, 13.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 778/938 [00:46<00:11, 13.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 782/938 [00:46<00:11, 14.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 784/938 [00:47<00:10, 14.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 788/938 [00:47<00:10, 14.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 792/938 [00:47<00:09, 14.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 794/938 [00:47<00:09, 14.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 798/938 [00:48<00:09, 14.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 800/938 [00:48<00:09, 14.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 804/938 [00:48<00:09, 14.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 806/938 [00:48<00:09, 14.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 810/938 [00:48<00:08, 14.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 812/938 [00:49<00:08, 14.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 816/938 [00:49<00:08, 14.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 818/938 [00:49<00:08, 14.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 822/938 [00:49<00:08, 14.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 824/938 [00:49<00:08, 13.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 828/938 [00:50<00:07, 13.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 830/938 [00:50<00:07, 14.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 834/938 [00:50<00:07, 13.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 836/938 [00:50<00:07, 13.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 840/938 [00:51<00:06, 14.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 842/938 [00:51<00:06, 14.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 846/938 [00:51<00:06, 14.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 848/938 [00:51<00:06, 13.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 852/938 [00:51<00:06, 13.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 854/938 [00:52<00:06, 13.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████▏| 858/938 [00:52<00:05, 14.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 860/938 [00:52<00:05, 13.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 864/938 [00:52<00:05, 13.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 866/938 [00:52<00:05, 13.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 870/938 [00:53<00:05, 12.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 872/938 [00:53<00:05, 12.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 876/938 [00:53<00:04, 12.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 878/938 [00:53<00:04, 12.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 882/938 [00:54<00:04, 12.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 884/938 [00:54<00:04, 12.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 888/938 [00:54<00:03, 12.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 890/938 [00:54<00:03, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 894/938 [00:55<00:03, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 896/938 [00:55<00:03, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 900/938 [00:55<00:02, 13.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 902/938 [00:55<00:02, 13.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 906/938 [00:56<00:02, 13.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 908/938 [00:56<00:02, 13.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 912/938 [00:56<00:01, 13.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 914/938 [00:56<00:01, 13.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 918/938 [00:56<00:01, 13.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 920/938 [00:57<00:01, 13.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 924/938 [00:57<00:01, 13.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 926/938 [00:57<00:00, 13.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 930/938 [00:57<00:00, 13.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 932/938 [00:57<00:00, 13.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 936/938 [00:58<00:00, 13.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "(10001, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:58<00:00, 16.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10001, 128)\n",
            "(10001, 128)\n",
            "[[-6.74103451  3.31183863  6.77172184 ...  7.98464394  8.82624531\n",
            "   2.77184153]\n",
            " [-0.8903172   5.4017458  -3.89691353 ... -2.63934517  0.263549\n",
            "  -0.7515372 ]\n",
            " [-0.46636561  2.06794238 -1.3430171  ... -0.67851067  0.19447768\n",
            "  -0.99652946]\n",
            " ...\n",
            " [ 1.92983949  0.0984416   1.24304998 ... -1.3124088   1.1472342\n",
            "   1.75869298]\n",
            " [-0.58496642  4.09034634  1.9091711  ...  6.40515518  7.54025793\n",
            "  -2.00339627]\n",
            " [-1.19568968  5.72017002 -4.2310524  ... -3.07495952  0.31577286\n",
            "  -1.33172333]]\n",
            "(60000, 128)\n",
            "47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test\n",
        "val_concat_label = np.empty(0)\n",
        "for i, data in enumerate(val_loader):\n",
        "        x, y = data\n",
        "        y_numpy = y.to(\"cpu\").detach().numpy().copy()\n",
        "        val_concat_label = np.concatenate( [val_concat_label,y_numpy])\n",
        "        #print(y_numpy)\n",
        "val_concat_label = val_concat_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MjTByznLHNM",
        "outputId": "f2cfdeb6-f700-4ae3-8787-fb5338b75bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "print(y_pred_test==-1)\n",
        "#print(\"val_concat_label\",val_concat_label[y_pred_test==-1])\n",
        "error_label = val_concat_label[y_pred_test==-1]\n",
        "print(\"error_label\",error_label)\n",
        "error_label_count = collections.Counter(error_label)\n",
        "print(\"error_label_count\",error_label_count)\n",
        "print(error_label_count[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heX-hmo3evaZ",
        "outputId": "4e6fbb6b-bc88-4564-c106-9e45ed8906cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False ... False False False]\n",
            "error_label [4. 4. 9. 8. 9. 3. 6. 4. 1. 5. 9. 7. 5. 7. 4. 8. 2. 8. 8. 1. 3. 8. 2. 5.\n",
            " 1. 5. 2. 7. 0. 1. 9. 1. 7. 9. 7. 2. 8. 6. 7. 3. 6. 7. 1. 7. 5. 5. 1. 1.\n",
            " 8. 1. 8. 3. 9. 6. 9. 8. 8. 8. 6. 1. 8. 1. 4. 8. 7. 4. 8. 0. 2. 0. 5. 2.\n",
            " 8. 1. 2. 8. 8. 1. 4. 7. 8. 3. 4. 8. 8. 1. 6. 6. 6. 9. 3. 9. 8. 8. 5. 4.\n",
            " 5. 5. 4. 1. 3. 5.]\n",
            "error_label_count Counter({8.0: 22, 1.0: 15, 5.0: 11, 4.0: 10, 7.0: 10, 9.0: 9, 6.0: 8, 3.0: 7, 2.0: 7, 0.0: 3})\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **validation setのそれぞれの画像枚数を数える**"
      ],
      "metadata": {
        "id": "dTWG0Twi1Q-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "val_dataset_label_list = []\n",
        "for dataset_index in range(len(val_set)):\n",
        "  val_dataset_label_list.append( val_set[dataset_index][1] )\n",
        "val_dataset_label_count = collections.Counter(val_dataset_label_list)\n",
        "print(val_dataset_label_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOJFzAfp1QFh",
        "outputId": "57bc32f3-2809-4580-bf2b-f4b1123f7b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 1135, 2: 1032, 7: 1028, 3: 1010, 9: 1009, 4: 982, 0: 980, 8: 974, 6: 958, 5: 892})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "owCA8pRI3pXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_error_dict = {}\n",
        "for key in val_dataset_label_count.keys():\n",
        "  if key in error_label_count:\n",
        "    error_rate = (error_label_count[key]/val_dataset_label_count[key]) * 100\n",
        "    result_error_dict[str(key)] = error_rate\n",
        "    #result_error_dict.setdefault(str(key),error_rate)\n",
        "  else:\n",
        "    error_rate = 0 * 100\n",
        "    result_error_dict[str(key)] = error_rate\n",
        "    #result_error_dict.setdefault(str(key),error_rate)\n",
        "result_error_dict = sorted(result_error_dict.items())\n",
        "result_error_dict = dict((x, y) for x, y in result_error_dict)\n",
        "print(result_error_dict)\n",
        "\n",
        "for kk, vv in result_error_dict.items():\n",
        "    print(\"key:\",kk,\"Error rate:\",vv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEbvyMca2ENR",
        "outputId": "228d684f-a57a-4519-b929-1bf300d594c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 0.30612244897959184, '1': 1.3215859030837005, '2': 0.6782945736434108, '3': 0.6930693069306931, '4': 1.0183299389002036, '5': 1.2331838565022422, '6': 0.8350730688935281, '7': 0.9727626459143969, '8': 2.2587268993839835, '9': 0.8919722497522299}\n",
            "key: 0 Error rate: 0.30612244897959184\n",
            "key: 1 Error rate: 1.3215859030837005\n",
            "key: 2 Error rate: 0.6782945736434108\n",
            "key: 3 Error rate: 0.6930693069306931\n",
            "key: 4 Error rate: 1.0183299389002036\n",
            "key: 5 Error rate: 1.2331838565022422\n",
            "key: 6 Error rate: 0.8350730688935281\n",
            "key: 7 Error rate: 0.9727626459143969\n",
            "key: 8 Error rate: 2.2587268993839835\n",
            "key: 9 Error rate: 0.8919722497522299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (label_name, judge_val) in enumerate(zip(val_concat_label, y_pred_test)):\n",
        "  if judge_val == -1:\n",
        "    print(\"data index\",i)\n",
        "    print(\"val_concat_label\",[val_concat_label[i]])"
      ],
      "metadata": {
        "id": "5alFYHPVh-xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_concat_label"
      ],
      "metadata": {
        "id": "3d4rWwMCjiKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, [( 1, 28, 28)])"
      ],
      "metadata": {
        "id": "o3Ht55q9f8bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "def get_mnist_loader(is_train: bool, batch_size: int) -> DataLoader:\n",
        "    trainset = datasets.FashionMNIST(\n",
        "                                root=\"./data\",\n",
        "                                train=is_train,\n",
        "                                transform=ToTensor(),\n",
        "                                download=True\n",
        "                              )\n",
        "    return DataLoader(trainset, batch_size=batch_size, shuffle=is_train)\n",
        "\n",
        "# data loder\n",
        "train_fashion_loader = get_mnist_loader(is_train=True, batch_size=64)"
      ],
      "metadata": {
        "id": "v3CpZKhff_Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fashion }MNIST testで実施\n",
        "\n",
        "val_results = np.zeros((1,100))\n",
        "for img, label in tqdm(train_fashion_loader):\n",
        "    img, label = img.to(device), label.to(device)\n",
        "    pred = model(img)\n",
        "    #print(pred.shape)\n",
        "    pred_num = pred.to(\"cpu\").detach().numpy().copy()\n",
        "    print(val_results.shape)\n",
        "    val_results = np.concatenate([val_results, pred_num])\n",
        "\n",
        "val_results_del = np.delete(val_results, 0, 0)\n",
        "print(val_results_del)\n",
        "print(val_results_del.shape)\n",
        "\n",
        "y_pred_test = clf.predict(val_results_del)\n",
        "n_error_test = y_pred_test[y_pred_test == -1].size\n",
        "print(n_error_test)"
      ],
      "metadata": {
        "id": "lQ-TqhEgg_1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPVNz01Ahjff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}